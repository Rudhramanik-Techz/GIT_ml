# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1puZqXXHaPy_4N2Gf3lxeBSYliARnEjdD
"""

import pandas as pd
df = pd.read_csv("/content/diabetes.csv")
df.head()

df['Outcome'].value_counts(normalize=True)

print("Original dataset size:", df.shape)

# Before cleaning
print("Before removing Glucose <= 0:", df.shape[0], "rows")

# Remove invalid Glucose
df = df[df['Glucose'] > 0]

# After cleaning
print("After removing Glucose <= 0:", df.shape[0], "rows removed:", df.shape[0] - df.shape[0])

print("Min Glucose:", df['Glucose'].min())

print("\nBefore removing BMI <= 0:", df.shape[0], "rows")

df = df[df['BMI'] > 0]

print("After removing BMI <= 0:", df.shape[0], "rows removed:", df.shape[0] - df.shape[0])
print("Min BMI:", df['BMI'].min())

print("\nBefore removing Insulin < 0:", df.shape[0], "rows")

df = df[df['Insulin'] >= 0]

print("After removing Insulin < 0:", df.shape[0], "rows removed:", df.shape[0] - df.shape[0])
print("Min Insulin:", df['Insulin'].min())

print("\nBefore removing BloodPressure <= 0:", df.shape[0], "rows")

df = df[df['BloodPressure'] > 0]

print("After removing BloodPressure <= 0:", df.shape[0], "rows removed:", df.shape[0] - df.shape[0])
print("Min BloodPressure:", df['BloodPressure'].min())

print("\nBefore removing SkinThickness < 0:", df.shape[0], "rows")

df = df[df['SkinThickness'] >= 0]

print("After removing SkinThickness < 0:", df.shape[0], "rows removed:", df.shape[0] - df.shape[0])
print("Min SkinThickness:", df['SkinThickness'].min())

df['Glucose_BMI'] = df['Glucose'] * df['BMI']
df['Age_BMI'] = df['Age'] * df['BMI']
df['Insulin_Glucose'] = df['Insulin'] / (df['Glucose'] + 1)

print("\nFeature Engineering Complete. Columns now:")
print(df.columns)
print(df.head())

from sklearn.model_selection import train_test_split

X = df.drop("Outcome", axis=1)
y = df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

from xgboost import XGBClassifier

neg = (y_train == 0).sum()
pos = (y_train == 1).sum()
scale = neg / pos

model = XGBClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=4,
    min_child_weight=3,
    gamma=0.2,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=scale,
    eval_metric="logloss",
    random_state=42
)

model.fit(X_train_res, y_train_res)

from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt

y_prob = model.predict_proba(X_test)[:,1]
y_pred = (y_prob > 0.6).astype(int)  # precision-oriented threshold

print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

precision, recall, _ = precision_recall_curve(y_test, y_prob)
pr_auc = auc(recall, precision)

plt.plot(recall, precision)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title(f"Precision–Recall Curve (AUC = {pr_auc:.2f})")
plt.show()

import numpy as np

cols_with_zero_as_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# Replace 0 with NaN
df[cols_with_zero_as_missing] = df[cols_with_zero_as_missing].replace(0, np.nan)

# Fill NaN with column median
df[cols_with_zero_as_missing] = df[cols_with_zero_as_missing].fillna(df[cols_with_zero_as_missing].median())

# Check again
print("Min values after fixing zeros:\n", df[cols_with_zero_as_missing].min())

df['Glucose_BMI'] = df['Glucose'] * df['BMI']
df['Age_BMI'] = df['Age'] * df['BMI']
df['Insulin_Glucose'] = df['Insulin'] / (df['Glucose'] + 1)

from sklearn.model_selection import train_test_split

X = df.drop("Outcome", axis=1)
y = df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

from xgboost import XGBClassifier

neg = (y_train == 0).sum()
pos = (y_train == 1).sum()
scale = neg / pos

model = XGBClassifier(
    n_estimators=600,
    learning_rate=0.05,
    max_depth=3,
    min_child_weight=2,
    gamma=0.1,
    subsample=0.85,
    colsample_bytree=0.85,
    scale_pos_weight=scale,
    eval_metric="aucpr",
    random_state=42
)

model.fit(X_train_res, y_train_res)

from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt

y_prob = model.predict_proba(X_test)[:,1]
y_pred = (y_prob > 0.5).astype(int)   # balanced threshold

print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

precision, recall, _ = precision_recall_curve(y_test, y_prob)
pr_auc = auc(recall, precision)

plt.plot(recall, precision)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title(f"Precision–Recall Curve (AUC = {pr_auc:.2f})")
plt.show()

